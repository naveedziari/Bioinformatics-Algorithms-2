{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_3 (logistic regression).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "a5eSFzm_NNvG"
      },
      "cell_type": "markdown",
      "source": [
        "# BME-230A: Homework 3 Part A\n",
        "\n",
        "Your assignment for homework 3A is to redo the linear regression analysis, but using a classification method from SKLearn.\n",
        "\n",
        "Use the same dataset:\n",
        "https://drive.google.com/file/d/1FZbQCEHr2Rie4cXSM6Udg0SaWTtPnEHO/view?usp=sharing\n",
        "\n",
        "Goals and Requirements:\n",
        "1. Select a classification method from [SKLearn](http://scikit-learn.org/):\n",
        "    1. I'd recommend logistics regression or any forest method as they are more intuitive. SVM would be a much more difficult method to understand.\n",
        "2. Write a short explanation of the method and how it works (look for explanations in documention, youtube, or online).\n",
        "3. Try to achieve the highest accuracy / estimator quality.\n",
        "\n",
        "*Notes*:\n",
        "\n",
        "Use a reasonable train/test split of 80%/20% or even 70%/30% to avoid too much variance in your estimate of accuracy, FPR and TPR. "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "bFp4Rq2BNNvH"
      },
      "cell_type": "markdown",
      "source": [
        "## Method\n",
        "Method Selected:\n",
        "\n",
        "Random Forest\n",
        "\n",
        "#### Short Description\n",
        "\n",
        "A random forest builds decision trees on the training set through bagging (bootstrap method - selection with replacement). During the tree construction, the algorithms performs a random subset of  \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "6v8hkGiMNNvI"
      },
      "cell_type": "markdown",
      "source": [
        "## Classification\n",
        "Create training/test splits and train the classifier"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "gQmwhhBeNNvJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "!pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# 2. Now proxy the Google Drive file to a local file\n",
        "cancer_data_import = drive.CreateFile({'id':'1FZbQCEHr2Rie4cXSM6Udg0SaWTtPnEHO'})\n",
        "cancer_data_import.GetContentFile('cancer_data.csv') # 'cancer_data.csv' is the file name that will be accessible in the notebook.\n",
        "\n",
        "# Read input\n",
        "df = pd.read_csv(\"cancer_data.csv\") #./data/breast-cancer-wisconsin.data.csv\")\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "for col in df.columns:\n",
        "    df[col] = encoder.fit_transform(df[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mtx4jCYFqyWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create Train/Test Split"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "vOH_TXTENNvQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X=df[['uniformity-of-cell-size', 'uniformity-of-cell-shape', 'single-epithelial-cell-size','bare-nuclei','bland-chromatin','normal-nucleoli']]  # Features\n",
        "y=df['class']  # Labels\n",
        "\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 80% training and 20% test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_4w7tb4rxL3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train Classifier on Training Set"
      ]
    },
    {
      "metadata": {
        "id": "Ssd57_83ruLo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#run the random forest\n",
        "clf=RandomForestClassifier(n_estimators=1000)\n",
        "clf.fit(X_train,y_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKNZD_oLtG8k",
        "colab_type": "code",
        "outputId": "064843b9-b3c9-47e8-ac3a-8479a6ab85a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(clf.feature_importances_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9857142857142858\n",
            "[0.28735294 0.24520227 0.11810531 0.09180321 0.16316388 0.09437239]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "vpiCuvguNNvS"
      },
      "cell_type": "markdown",
      "source": [
        "## Questions\n",
        "What feature contributes most to the prediction? How can we tell?"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "YmpTtiemNNvT"
      },
      "cell_type": "markdown",
      "source": [
        "The most important feature is uniformity of cell size (the second column/entry). We can tell because the random forest constructs its decision trees based on the importance of the features (and the package has a function to return feature importances)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "zlDc9idyNNvU"
      },
      "cell_type": "markdown",
      "source": [
        "Explain in your own words the difference between regression and classification methods.\n",
        "\n",
        "A regression aims to predict a continuous dependent variable (e.g. housing price) while classification aims to predict a discrete state/variable (e.g. which cluster a gene belongs to)"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "GaZLWMMjNNvV"
      },
      "cell_type": "markdown",
      "source": [
        "Is it best to use all the features or exclude some? Why do you think?\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "deletable": true,
        "editable": true,
        "id": "7Kwmwj5SNNvX"
      },
      "cell_type": "markdown",
      "source": [
        "It is oftentimes best to forgo some features because it may cause overfitting.\n",
        "\n"
      ]
    }
  ]
}